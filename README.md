# NutriDiscrete-NLP
Pipeline NLP: Clasificaci√≥n sem√°ntica masiva (Zero-Shot/BART) y an√°lisis de frecuencias con aceleraci√≥n GPU.
# üìã NutriDiscrete-NLP - An√°lisis Completo del Proyecto

## üìå Resumen Ejecutivo

**NutriDiscrete-NLP** es un pipeline de procesamiento de lenguaje natural (NLP) acelerado por GPU que clasifica autom√°ticamente documentos cient√≠ficos sobre nutrici√≥n en 5 categor√≠as tem√°ticas usando clasificaci√≥n Zero-Shot con el modelo BART.

**Tecnolog√≠as principales:**
- PyTorch con GPU CUDA
- Transformers (facebook/bart-large-mnli)
- NLTK para tokenizaci√≥n
- TensorFlow (para modelos secundarios)

---

## üìÅ Estructura del Proyecto

```
NutriDiscrete-NLP/
‚îú‚îÄ‚îÄ main.py                              # ‚≠ê Pipeline principal de clasificaci√≥n NLP
‚îú‚îÄ‚îÄ borrar.py                            # Modelo Siamese para matching (TensorFlow)
‚îú‚îÄ‚îÄ requirements.txt                     # Dependencias del proyecto
‚îú‚îÄ‚îÄ README.md                            # Descripci√≥n breve del proyecto
‚îú‚îÄ‚îÄ LICENSE                              # Licencia del proyecto
‚îú‚îÄ‚îÄ .git/                                # Repositorio Git
‚îú‚îÄ‚îÄ .gitattributes                       # Configuraci√≥n de Git
‚îú‚îÄ‚îÄ .venv/ & env/                        # Entornos virtuales de Python
‚îî‚îÄ‚îÄ Datos/                               # Carpeta de datos
    ‚îú‚îÄ‚îÄ nutricion_1000_fuentes.json      # üì• Input: 1094 documentos fuentes
    ‚îú‚îÄ‚îÄ nutricion_procesada_gpu.json     # üì§ Output: Documentos clasificados
    ‚îî‚îÄ‚îÄ informe_procesamiento.md         # üìä Informe de estad√≠sticas
```

---

## üéØ Funcionalidad de `main.py`

### **Prop√≥sito**
Procesar masivamente ~1000 documentos cient√≠ficos sobre nutrici√≥n clasific√°ndolos en 5 temas usando una red neuronal preentrenada.

### **Flujo de Ejecuci√≥n**

#### 1. **Configuraci√≥n Inicial**
```python
- Descarga recursos NLTK (stopwords, punkt)
- Detecta disponibilidad de GPU (CUDA)
- Carga modelo BART-Large (facebook/bart-large-mnli)
- Define 5 temas: nutrition, longevity, health, strength, mobility
```

#### 2. **Preparaci√≥n de Datos**
```python
- Lee JSON con 1094 documentos
- Extrae abstracts v√°lidos (texto > 20 caracteres)
- Genera lista de referencia de objetos originales
- Total v√°lidos: 1094 documentos
```

#### 3. **Inferencia Masiva (GPU)**
```python
- Batch size: 16 (procesa 16 documentos simult√°neamente)
- Modelo: facebook/bart-large-mnli (clasificaci√≥n Zero-Shot)
- Entrada: Abstracto de documento + 5 labels tem√°ticos
- Salida: Tema clasificado + score de confianza (0-1)
```

#### 4. **Post-Procesamiento**
```python
- Integra resultados en JSON original
- Agrega metadatos:
  * target_partition: C√≥digo del tema (NUT, LON, HEA, STR, MOB)
  * ai_detected_topic: Tema detectado
  * confidence_score: Score 0-1
  * status: "processed" / "skipped_empty" / "error"
```

#### 5. **An√°lisis de Patrones**
```python
- Tokenizaci√≥n con NLTK
- Limpieza: stop-words + ruido espec√≠fico del dominio
- Top palabras por tema (top 8)
- Top palabras globales (top 15)
- Conteos de documentos por tema
- Confianza promedio por tema
```

#### 6. **Generaci√≥n de Reportes**
```python
- Archivo JSON: nutricion_procesada_gpu.json
- Reporte Markdown: informe_procesamiento.md
- M√©tricas: Conteos, distribuci√≥n, estad√≠sticas
```

### **Salidas Generadas**

#### üìä Distribuci√≥n Tem√°tica (Resultados Reales)
| Tema | Documentos | % | Confianza Media |
|------|-----------|---|-----------------|
| nutrition | 377 | 34.46% | 0.546 |
| health | 332 | 30.35% | 0.488 |
| longevity | 172 | 15.72% | 0.542 |
| strength | 152 | 13.89% | 0.473 |
| mobility | 61 | 5.58% | 0.462 |

#### üî§ Top Palabras Globales
1. diet (1575)
2. sarcopenia (1433)
3. muscle (1307)
4. metabolic (960)
5. risk (942)
6. disease (812)
7. aging (800)
8. nutrition (755)

---

## ü§ñ Funcionalidad de `borrar.py`

### **Prop√≥sito**
Demostraci√≥n de un modelo Siamese con embeddings para matching usuario-empresa considerando:
- Skills t√©cnicos
- Nivel de idioma (Ingl√©s: B√°sico, Intermedio, Avanzado)
- Certificaciones
- Edad

### **Caracter√≠sticas**

#### 1. **Diccionario de Tags Expandido**
```python
Tecnolog√≠as: Python, Java, SQL, C++, JavaScript, etc.
Idiomas: 
  - Ingl√©s (B√°sico, Intermedio, Avanzado)
  - Espa√±ol, Franc√©s, Alem√°n, Chino, Portugu√©s

Pesos por certificaci√≥n:
  - CON certificado: 1.0
  - SIN certificado: 0.5
```

#### 2. **Arquitectura Siamese**
```
Usuario/Empresa
    ‚Üì
[IDs Tags] ‚Üí Embedding ‚Üí Ponderaci√≥n
[Pesos]    
[Geo]      ‚Üí Concatenaci√≥n ‚Üí Dense(16) ‚Üí Dense(4) ‚Üí L2 Norm
[Edad]     
```

#### 3. **Datos de Ejemplo**
```
Usuarios (5):
- Sr. Pro (35 a√±os, Ingl√©s Avanzado certificado)
- Jr. Novato (22 a√±os, Ingl√©s B√°sico sin cert)
- Veterano Manager (50 a√±os)

Empresas (5):
- Lead Position (requiere Ingl√©s Avanzado)
- Becario (acepta Ingl√©s B√°sico)
- Call Center (solo Ingl√©s)
- Direcci√≥n (requiere Liderazgo + edad madura)
```

#### 4. **Salidas**
- Matriz de similitud coseno (usuarios vs empresas)
- Top 2 mejores matches por usuario
- Top 2 mejores candidatos por empresa
- Gr√°fico PCA 2D con l√≠neas de matches

---

## üì¶ Dependencias por M√≥dulo

### **main.py requiere:**
```
‚úÖ torch (GPU support)
‚úÖ transformers (BART model)
‚úÖ nltk (NLP utilities)
‚úÖ tqdm (progress bars)
‚úÖ json (built-in)
‚úÖ os (built-in)
‚úÖ collections (built-in)
‚úÖ datetime (built-in)
```

### **borrar.py requiere:**
```
‚úÖ numpy
‚úÖ tensorflow & keras
‚úÖ matplotlib
‚úÖ scikit-learn (PCA, cosine_similarity)
```

### **Todos requieren:**
```
‚úÖ certifi, charset-normalizer, requests
‚úÖ huggingface-hub (descargar modelos)
‚úÖ safetensors
```

---

## üöÄ Gu√≠a de Instalaci√≥n y Ejecuci√≥n

### **Paso 1: Crear Entorno Virtual**
```powershell
python -m venv env
env\Scripts\Activate.ps1
```

### **Paso 2: Instalar Dependencias**
```powershell
pip install -r requirements.txt
```

### **Paso 3: GPU Support (Opcional pero recomendado)**
```powershell
# Si tienes NVIDIA CUDA 12.1:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### **Paso 4: Ejecutar Pipeline**
```powershell
# Clasificaci√≥n de documentos
python main.py

# Demostraci√≥n de matching (opcional)
python borrar.py
```

---

## üìä Archivos de Datos

### **Entrada: `nutricion_1000_fuentes.json`**
```json
{
  "content": {
    "abstract": "texto del documento..."
  },
  "nlp_processing": {} // Se agrega durante ejecuci√≥n
}
```

### **Salida: `nutricion_procesada_gpu.json`**
```json
{
  "content": {
    "abstract": "texto del documento..."
  },
  "nlp_processing": {
    "target_partition": "NUT",
    "ai_detected_topic": "nutrition",
    "confidence_score": 0.7234,
    "status": "processed"
  }
}
```

### **Reporte: `informe_procesamiento.md`**
```markdown
# Resumen Num√©rico
- Total documentos: 1094
- Procesados: 1094
- Skipped: 0
- Errores: 0

# Distribuci√≥n por Tema + Confianza media
# Top palabras por Tema
# Top palabras Globales
```

---

## üîß Configuraciones Importantes

### En `main.py`:

```python
# Temas de clasificaci√≥n
mis_temas = ["nutrition", "longevity", "health", "strength", "mobility"]

# Batch size para GPU (aumentar si hay memoria disponible)
batch_size=16  # Para procesar m√°s documentos en paralelo

# Detecci√≥n autom√°tica de GPU
device = 0 if torch.cuda.is_available() else -1

# Stop-words personalizados para dominio de nutrici√≥n
palabras_ruido = {'study', 'results', 'data', 'abstract', ...}

# Rutas de entrada/salida (ajustar seg√∫n tu sistema)
ruta_entrada = r"C:\Users\...\nutricion_1000_fuentes.json"
```

### En `borrar.py`:

```python
# N√∫mero de tags m√°ximo
NUM_TAGS = 100000008
EMBEDDING_DIM = 8

# Pesos por certificaci√≥n (Ingl√©s)
sin_certificado = 0.5
con_certificado = 1.0

# Epochs de entrenamiento
epochs=150
```

---

## üìà M√©tricas y KPIs

### **Rendimiento**
- **Documentos procesados**: 1094 ‚úÖ
- **Tasa de √©xito**: 100% (0 errores)
- **Velocidad**: Depende de GPU (~1000 docs en 5-30 minutos seg√∫n hardware)

### **Calidad**
- **Confianza media global**: ~0.51 (muy aceptable para Zero-Shot)
- **Distribuci√≥n balanceada**: S√≠ (nutrition 34%, health 30%, otros 36%)
- **Cobertura tem√°tica**: 5 categor√≠as bien distribuidas

### **Datos**
- **Documentos fuentes**: 1094
- **Documentos v√°lidos**: 1094 (100%)
- **Campos procesados**: abstract
- **Metadatos generados**: 4 por documento

---

## üêõ Manejo de Errores

| Error | Soluci√≥n |
|-------|----------|
| `GPU no detectada` | Instalar torch con CUDA: `pip install torch --index-url https://download.pytorch.org/whl/cu121` |
| `NLTK resources missing` | Script descarga autom√°ticamente en ejecuci√≥n |
| `File not found` | Verificar ruta en `ruta_entrada` |
| `Memory error` | Reducir `batch_size` de 16 a 8 o 4 |
| `Model download fails` | Verificar conexi√≥n a internet y espacio en disco (~6GB) |

---

## üí° Mejoras Futuras

- [ ] Agregar validaci√≥n cruzada de clasificaciones
- [ ] Implementar fine-tuning con datos etiquetados
- [ ] Exportar resultados a m√∫ltiples formatos (CSV, Parquet)
- [ ] Dashboard interactivo con Streamlit
- [ ] Pruebas unitarias automatizadas
- [ ] CI/CD con GitHub Actions
- [ ] Documentaci√≥n de API REST

---

## üìù Notas de Desarrollo

- **Lenguaje**: Python 3.8+
- **Versi√≥n del Modelo**: facebook/bart-large-mnli (descargar ~1.6GB)
- **GPU m√≠nima**: 2GB VRAM (recomendado 4GB+)
- **CPU m√≠nima**: Funciona pero muy lento (~1h para 1000 docs)
- **Licencia**: Revisar LICENSE
- **Repositorio**: `.git` configurado

---

## üë§ Contacto y Soporte

Este proyecto es parte de: **NutriDiscrete-NLP**
- GitHub: Eddyfals0
- Rama principal: main

---

*Generado: 2025-11-24 | Versi√≥n: 1.0*
